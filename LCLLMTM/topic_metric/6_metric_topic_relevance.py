#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸»é¢˜æ–‡æœ¬ç›¸å…³æ€§/å¹»è§‰çŽ‡è¯„ä¼°æŒ‡æ ‡

è¿™ä¸ªæŒ‡æ ‡ç›´æŽ¥æŠŠä¸»é¢˜çš„å…³é”®è¯keywordsé‚£ä¸€åˆ—å’Œæ–‡æœ¬çš„å…³é”®è¯æ¯”å¯¹
å¦‚æžœå‡ºçŽ°é‡å¤çš„é‚£å°±æ˜¯ç›¸å…³çš„ï¼Œç”¨äºŽæ£€æµ‹ä¸»é¢˜ç”Ÿæˆçš„å¹»è§‰çŽ‡
"""

import json
import pandas as pd
import numpy as np
from typing import Dict, Any, List, Set
import os
import re
from collections import Counter

# é…ç½®åŒºåŸŸ
CSV_FILE = "C:/Users/1/Desktop/TopMost/LCLLMTM/data4LCLLM/NYT_sampled.csv"

def extract_keywords_from_text(text: str) -> Set[str]:
    """
    ä»Žæ–‡æœ¬ä¸­æå–å…³é”®è¯
    
    Args:
        text (str): è¾“å…¥æ–‡æœ¬
        
    Returns:
        Set[str]: å…³é”®è¯é›†åˆ
    """
    # ç®€å•çš„å…³é”®è¯æå–ï¼šåŽ»é™¤æ ‡ç‚¹ç¬¦å·ï¼Œè½¬æ¢ä¸ºå°å†™ï¼Œåˆ†å‰²å•è¯
    words = re.findall(r'\b[a-zA-Z]{3,}\b', text.lower())
    # è¿‡æ»¤å¸¸è§åœç”¨è¯
    stop_words = {'the', 'and', 'for', 'are', 'but', 'not', 'you', 'all', 'can', 'had', 'her', 'was', 'one', 'our', 'out', 'day', 'get', 'has', 'him', 'his', 'how', 'its', 'may', 'new', 'now', 'old', 'see', 'two', 'who', 'boy', 'did', 'man', 'men', 'put', 'say', 'she', 'too', 'use'}
    keywords = set(word for word in words if word not in stop_words and len(word) > 3)
    return keywords

def analyze_topic_relevance(csv_file: str) -> Dict[str, Any]:
    """
    åˆ†æžä¸»é¢˜æ–‡æœ¬ç›¸å…³æ€§/å¹»è§‰çŽ‡
    
    Args:
        csv_file (str): åŒ…å«topicå’Œkeywordsåˆ—çš„CSVæ–‡ä»¶è·¯å¾„
        
    Returns:
        Dict: åˆ†æžç»“æžœ
    """
    print("ðŸ” åˆ†æžä¸»é¢˜æ–‡æœ¬ç›¸å…³æ€§/å¹»è§‰çŽ‡...")
    print(f"   ðŸ“ CSVæ–‡ä»¶: {csv_file}")
    
    try:
        # è¯»å–CSVæ–‡ä»¶
        df = pd.read_csv(csv_file)
        
        # æ£€æŸ¥å¿…éœ€çš„åˆ—
        required_columns = ['text', 'keywords']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            return {"error": f"CSVæ–‡ä»¶ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing_columns}"}
        
        # å¦‚æžœæœ‰topicåˆ—ï¼Œä¹Ÿä½¿ç”¨å®ƒ
        has_topic_column = 'topic' in df.columns
        
        relevance_scores = []
        hallucination_cases = []
        detailed_analysis = []
        
        print(f"   ðŸ“Š åˆ†æž {len(df)} è¡Œæ•°æ®...")
        
        for idx, row in df.iterrows():
            try:
                # èŽ·å–æ–‡æœ¬å’Œå…³é”®è¯
                text = str(row['text']) if pd.notna(row['text']) else ""
                keywords_str = str(row['keywords']) if pd.notna(row['keywords']) else ""
                topic = str(row['topic']) if has_topic_column and pd.notna(row['topic']) else ""
                
                # è§£æžå…³é”®è¯ï¼ˆå‡è®¾æ˜¯JSONæ ¼å¼çš„åˆ—è¡¨ï¼‰
                try:
                    if keywords_str.startswith('[') and keywords_str.endswith(']'):
                        # JSONæ ¼å¼
                        keywords_list = json.loads(keywords_str)
                    else:
                        # é€—å·åˆ†éš”æ ¼å¼
                        keywords_list = [kw.strip().strip("'\"") for kw in keywords_str.split(',')]
                    
                    # æ¸…ç†å’Œæ ‡å‡†åŒ–å…³é”®è¯
                    topic_keywords = set()
                    for kw in keywords_list:
                        if isinstance(kw, str) and kw.strip():
                            topic_keywords.add(kw.strip().lower())
                
                except (json.JSONDecodeError, ValueError):
                    # å¦‚æžœè§£æžå¤±è´¥ï¼Œå°è¯•ç®€å•åˆ†å‰²
                    keywords_list = keywords_str.split(',')
                    topic_keywords = set(kw.strip().lower() for kw in keywords_list if kw.strip())
                
                # ä»Žæ–‡æœ¬ä¸­æå–å…³é”®è¯
                text_keywords = extract_keywords_from_text(text)
                
                # æ·»åŠ ä¸»é¢˜è¯åˆ°å…³é”®è¯é›†åˆ
                if topic:
                    topic_words = extract_keywords_from_text(topic)
                    topic_keywords.update(topic_words)
                
                # è®¡ç®—é‡å å…³é”®è¯
                overlap_keywords = topic_keywords.intersection(text_keywords)
                
                # è®¡ç®—ç›¸å…³æ€§å¾—åˆ†
                if len(topic_keywords) > 0:
                    relevance_score = len(overlap_keywords) / len(topic_keywords)
                else:
                    relevance_score = 0
                
                # è®¡ç®—å¹»è§‰å…³é”®è¯ï¼ˆä¸»é¢˜ä¸­æœ‰ä½†æ–‡æœ¬ä¸­æ²¡æœ‰çš„å…³é”®è¯ï¼‰
                hallucination_keywords = topic_keywords - text_keywords
                hallucination_ratio = len(hallucination_keywords) / len(topic_keywords) if len(topic_keywords) > 0 else 0
                
                relevance_scores.append(relevance_score)
                
                # è®°å½•è¯¦ç»†åˆ†æž
                analysis_detail = {
                    "row_index": idx,
                    "topic_keywords_count": len(topic_keywords),
                    "text_keywords_count": len(text_keywords),
                    "overlap_count": len(overlap_keywords),
                    "relevance_score": round(relevance_score, 4),
                    "hallucination_ratio": round(hallucination_ratio, 4),
                    "overlap_keywords": list(overlap_keywords),
                    "hallucination_keywords": list(hallucination_keywords)
                }
                detailed_analysis.append(analysis_detail)
                
                # è®°å½•ä¸¥é‡å¹»è§‰æ¡ˆä¾‹
                if hallucination_ratio > 0.5:  # è¶…è¿‡50%çš„å…³é”®è¯æ˜¯å¹»è§‰
                    hallucination_cases.append({
                        "row_index": idx,
                        "hallucination_ratio": hallucination_ratio,
                        "hallucination_keywords": list(hallucination_keywords),
                        "topic": topic[:100] if topic else "N/A",
                        "text_preview": text[:200] if text else "N/A"
                    })
                
            except Exception as e:
                print(f"   âš ï¸ å¤„ç†ç¬¬ {idx} è¡Œæ—¶å‡ºé”™: {str(e)}")
                continue
        
        if not relevance_scores:
            return {"error": "æ²¡æœ‰æˆåŠŸåˆ†æžçš„æ•°æ®è¡Œ"}
        
        # è®¡ç®—æ•´ä½“ç»Ÿè®¡
        mean_relevance = np.mean(relevance_scores)
        median_relevance = np.median(relevance_scores)
        std_relevance = np.std(relevance_scores)
        
        # è®¡ç®—å¹»è§‰çŽ‡ç»Ÿè®¡
        hallucination_ratios = [detail['hallucination_ratio'] for detail in detailed_analysis]
        mean_hallucination = np.mean(hallucination_ratios)
        
        # åˆ†ç±»è¯„ä¼°
        high_relevance_count = sum(1 for score in relevance_scores if score >= 0.7)
        medium_relevance_count = sum(1 for score in relevance_scores if 0.3 <= score < 0.7)
        low_relevance_count = sum(1 for score in relevance_scores if score < 0.3)
        
        results = {
            "metric_name": "ä¸»é¢˜æ–‡æœ¬ç›¸å…³æ€§/å¹»è§‰çŽ‡",
            "total_analyzed": len(relevance_scores),
            "mean_relevance_score": round(mean_relevance, 4),
            "median_relevance_score": round(median_relevance, 4),
            "std_relevance_score": round(std_relevance, 4),
            "mean_hallucination_ratio": round(mean_hallucination, 4),
            "relevance_distribution": {
                "high_relevance": high_relevance_count,
                "medium_relevance": medium_relevance_count,
                "low_relevance": low_relevance_count,
                "high_relevance_percentage": round(high_relevance_count / len(relevance_scores) * 100, 2),
                "low_relevance_percentage": round(low_relevance_count / len(relevance_scores) * 100, 2)
            },
            "hallucination_analysis": {
                "severe_hallucination_cases": len(hallucination_cases),
                "severe_hallucination_percentage": round(len(hallucination_cases) / len(relevance_scores) * 100, 2)
            },
            "evaluation": {
                "relevance_quality": "ä¼˜ç§€" if mean_relevance >= 0.7 else "è‰¯å¥½" if mean_relevance >= 0.5 else "ä¸€èˆ¬" if mean_relevance >= 0.3 else "è¾ƒå·®",
                "hallucination_severity": "è½»å¾®" if mean_hallucination <= 0.2 else "ä¸­ç­‰" if mean_hallucination <= 0.4 else "ä¸¥é‡",
                "overall_assessment": "ä¼˜ç§€" if mean_relevance >= 0.6 and mean_hallucination <= 0.3 else "è‰¯å¥½" if mean_relevance >= 0.4 and mean_hallucination <= 0.5 else "éœ€æ”¹è¿›"
            },
            "sample_hallucination_cases": hallucination_cases[:5],  # æ˜¾ç¤ºå‰5ä¸ªä¸¥é‡æ¡ˆä¾‹
            "detailed_statistics": {
                "min_relevance": round(min(relevance_scores), 4),
                "max_relevance": round(max(relevance_scores), 4),
                "relevance_scores_sample": relevance_scores[:10]  # å‰10ä¸ªå¾—åˆ†æ ·ä¾‹
            }
        }
        
        # è¾“å‡ºç»“æžœ
        print(f"\nðŸ” ä¸»é¢˜æ–‡æœ¬ç›¸å…³æ€§/å¹»è§‰çŽ‡åˆ†æžç»“æžœ:")
        print(f"   ðŸ“Š åˆ†æžæ ·æœ¬æ•°: {results['total_analyzed']}")
        print(f"   ðŸ“Š å¹³å‡ç›¸å…³æ€§å¾—åˆ†: {results['mean_relevance_score']:.4f}")
        print(f"   ðŸ“Š å¹³å‡å¹»è§‰çŽ‡: {results['mean_hallucination_ratio']:.4f}")
        print(f"   ðŸ“Š é«˜ç›¸å…³æ€§æ¯”ä¾‹: {results['relevance_distribution']['high_relevance_percentage']:.1f}%")
        print(f"   ðŸ“Š ä½Žç›¸å…³æ€§æ¯”ä¾‹: {results['relevance_distribution']['low_relevance_percentage']:.1f}%")
        print(f"   ðŸ“Š ä¸¥é‡å¹»è§‰æ¡ˆä¾‹: {results['hallucination_analysis']['severe_hallucination_cases']} ä¸ª")
        print(f"   ðŸ“Š ç›¸å…³æ€§è´¨é‡: {results['evaluation']['relevance_quality']}")
        print(f"   ðŸ“Š å¹»è§‰ä¸¥é‡ç¨‹åº¦: {results['evaluation']['hallucination_severity']}")
        print(f"   ðŸ“Š æ•´ä½“è¯„ä¼°: {results['evaluation']['overall_assessment']}")
        
        return results
        
    except FileNotFoundError:
        return {"error": f"æ–‡ä»¶æœªæ‰¾åˆ°: {csv_file}"}
    except pd.errors.EmptyDataError:
        return {"error": "CSVæ–‡ä»¶ä¸ºç©º"}
    except Exception as e:
        return {"error": f"åˆ†æžè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"}

def save_results(results: Dict[str, Any], output_file: str = "topic_relevance_results.json"):
    """ä¿å­˜ç»“æžœåˆ°æ–‡ä»¶"""
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = "C:/Users/1/Desktop/TopMost/metric_result"
        os.makedirs(output_dir, exist_ok=True)

        # æž„å»ºå®Œæ•´è·¯å¾„
        full_path = os.path.join(output_dir, output_file)

        with open(full_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"\nðŸ’¾ ç»“æžœå·²ä¿å­˜åˆ°: {full_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜ç»“æžœå¤±è´¥: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    print("ðŸš€ ä¸»é¢˜æ–‡æœ¬ç›¸å…³æ€§/å¹»è§‰çŽ‡è¯„ä¼°")
    print("="*60)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(CSV_FILE):
        print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {CSV_FILE}")
        return
    
    # è¿è¡Œåˆ†æž
    results = analyze_topic_relevance(CSV_FILE)
    
    if "error" in results:
        print(f"âŒ åˆ†æžå¤±è´¥: {results['error']}")
        return
    
    # ä¿å­˜ç»“æžœ
    save_results(results)
    
    print("\nðŸŽ‰ åˆ†æžå®Œæˆï¼")

if __name__ == "__main__":
    main()
