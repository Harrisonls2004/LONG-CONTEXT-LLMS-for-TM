#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLMä¸»é¢˜åˆ†æç»“æœè¯„æµ‹æ¨¡å—
åˆå¹¶RLForTopicå’ŒTopMostçš„è¯„æµ‹æŒ‡æ ‡ï¼Œé€‚é…LLMè¾“å‡ºç»“æœ
"""

import numpy as np
import math
from typing import List, Dict, Tuple, Optional
from collections import Counter, defaultdict
from itertools import combinations
import warnings
warnings.filterwarnings('ignore')

class TraTopicEvaluator:
    """LLMä¸»é¢˜åˆ†æç»“æœè¯„æµ‹å™¨"""
    
    def __init__(self, reference_corpus: List[str] = None):
        """
        åˆå§‹åŒ–è¯„æµ‹å™¨
        
        Args:
            reference_corpus: å‚è€ƒè¯­æ–™åº“ï¼ˆç”¨äºè®¡ç®—NPMIç­‰æŒ‡æ ‡ï¼‰
        """
        self.reference_corpus = reference_corpus
        self.word_counts = None
        self.doc_counts = None
        self.total_docs = 0
        
        if reference_corpus:
            self._build_corpus_stats()
    
    def _build_corpus_stats(self):
        """æ„å»ºè¯­æ–™åº“ç»Ÿè®¡ä¿¡æ¯"""
        self.word_counts = Counter()
        self.doc_counts = Counter()
        self.total_docs = len(self.reference_corpus)
        
        for doc in self.reference_corpus:
            words = doc.lower().split()
            doc_words = set(words)
            
            for word in words:
                self.word_counts[word] += 1
            
            for word in doc_words:
                self.doc_counts[word] += 1
    
    def evaluate_all(self, topics: List[Dict], topk: int = 8) -> Dict[str, float]:
        """
        ç»¼åˆè¯„æµ‹æ‰€æœ‰æŒ‡æ ‡ - åªä½¿ç”¨ç¡®å®å¯ç”¨çš„è¯„æµ‹æŒ‡æ ‡

        Args:
            topics: LLMè¾“å‡ºçš„ä¸»é¢˜åˆ—è¡¨ï¼Œæ¯ä¸ªä¸»é¢˜åŒ…å«keywordså­—æ®µ
            topk: è¯„æµ‹æ—¶ä½¿ç”¨çš„top-kå…³é”®è¯æ•°é‡

        Returns:
            åŒ…å«æ‰€æœ‰è¯„æµ‹æŒ‡æ ‡çš„å­—å…¸
        """
        results = {}

        # æå–ä¸»é¢˜è¯åˆ—è¡¨
        topic_words = []
        for topic in topics:
            keywords = topic.get('keywords', [])[:topk]
            topic_words.append(keywords)

        # ========== 4ç§å¯ç”¨è¯„æµ‹æŒ‡æ ‡ ==========
        # 1. ä¸»é¢˜å¤šæ ·æ€§ (Topic Diversity) - TopMost âœ…
        results['topic_diversity'] = self.calculate_topic_diversity(topic_words)

        # # 2. RBOç›¸ä¼¼åº¦ (Rank-Biased Overlap) - RL-for-topic âœ…
        # if len(topic_words) >= 4:  # è‡³å°‘éœ€è¦4ä¸ªä¸»é¢˜æ‰èƒ½åˆ†æˆä¸¤ç»„
        #     # å°†ä¸»é¢˜åˆ—è¡¨åˆ†æˆä¸¤åŠè¿›è¡ŒRBOæ¯”è¾ƒ
        #     mid = len(topic_words) // 2
        #     topic_words_1 = topic_words[:mid]
        #     topic_words_2 = topic_words[mid:mid*2]  # ç¡®ä¿ä¸¤ä¸ªåˆ—è¡¨é•¿åº¦ç›¸åŒ
        #     if len(topic_words_1) == len(topic_words_2) and len(topic_words_1) > 0:
        #         results['rbo_similarity'] = self.calculate_rbo(topic_words_1, topic_words_2)
        # else:
        #     results['rbo_similarity'] = None  # ä¸»é¢˜æ•°é‡ä¸è¶³

        # 3. Word2Vecè¿è´¯æ€§ - RL-for-topic âœ… (å¯é€‰)
        # try:
            # results['word2vec_coherence'] = self.calculate_word2vec_coherence(topic_words)
        # except:
        #     results['word2vec_coherence'] = None

        # 4. NPMIè¿è´¯æ€§ (window=10) - RL-for-topic âœ…
        if self.reference_corpus:
            results['npmi_coherence_window'] = self.calculate_npmi_coherence_window(topic_words, window_size=10)


        return results
    
    def calculate_topic_diversity(self, topic_words: List[List[str]]) -> float:
        """
        è®¡ç®—ä¸»é¢˜å¤šæ ·æ€§ (Topic Diversity) - TopMostæ ‡å‡†å®ç°
        TD = |unique_words| / |total_words|

        Args:
            topic_words: æ¯ä¸ªä¸»é¢˜çš„å…³é”®è¯åˆ—è¡¨

        Returns:
            å¤šæ ·æ€§åˆ†æ•° (0-1ï¼Œè¶Šé«˜è¶Šå¥½)
        """
        if not topic_words:
            return 0.0

        all_words = set()
        total_words = 0

        for words in topic_words:
            all_words.update(words)
            total_words += len(words)

        if total_words == 0:
            return 0.0

        return len(all_words) / total_words

    def calculate_word_uniqueness(self, topic_words: List[List[str]]) -> float:
        """
        è®¡ç®—è¯æ±‡ç‹¬ç‰¹æ€§ - TopMostæŒ‡æ ‡
        è¡¡é‡åªå‡ºç°åœ¨ä¸€ä¸ªä¸»é¢˜ä¸­çš„è¯æ±‡æ¯”ä¾‹
        """
        if not topic_words:
            return 0.0

        word_freq = Counter()
        for words in topic_words:
            for word in words:
                word_freq[word] += 1

        unique_words = sum(1 for count in word_freq.values() if count == 1)
        total_unique_words = len(word_freq)

        return unique_words / total_unique_words if total_unique_words > 0 else 0.0
    
    def calculate_unique_words_ratio(self, topic_words: List[List[str]]) -> float:
        """è®¡ç®—ç‹¬ç‰¹è¯æ±‡æ¯”ä¾‹"""
        if not topic_words:
            return 0.0
        
        word_freq = Counter()
        for words in topic_words:
            for word in words:
                word_freq[word] += 1
        
        unique_words = sum(1 for count in word_freq.values() if count == 1)
        total_words = len(word_freq)
        
        return unique_words / total_words if total_words > 0 else 0.0

    def calculate_word2vec_coherence(self, topic_words: List[List[str]]) -> float:
        """
        è®¡ç®—Word2Vecè¿è´¯æ€§ - RL-for-topic-modelsæ ‡å‡†æŒ‡æ ‡
        ä½¿ç”¨è¯å‘é‡ä½™å¼¦ç›¸ä¼¼åº¦è¡¡é‡ä¸»é¢˜å†…è¯çš„è¯­ä¹‰ä¸€è‡´æ€§
        """
        try:
            # å°è¯•å¯¼å…¥gensimå’Œä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
            import gensim.downloader as api

            # ä½¿ç”¨é¢„è®­ç»ƒçš„Word2Vecæ¨¡å‹
            model = api.load("word2vec-google-news-300")

            coherence_scores = []

            for words in topic_words:
                if len(words) < 2:
                    continue

                # è¿‡æ»¤æ¨¡å‹ä¸­å­˜åœ¨çš„è¯
                valid_words = [word for word in words if word in model.key_to_index]

                if len(valid_words) < 2:
                    continue

                # è®¡ç®—è¯å¯¹çš„ä½™å¼¦ç›¸ä¼¼åº¦
                similarities = []
                for i in range(len(valid_words)):
                    for j in range(i + 1, len(valid_words)):
                        try:
                            sim = model.similarity(valid_words[i], valid_words[j])
                            similarities.append(sim)
                        except:
                            continue

                if similarities:
                    coherence_scores.append(np.mean(similarities))

            return np.mean(coherence_scores) if coherence_scores else 0.0

        except Exception as e:
            # å¦‚æœæ— æ³•åŠ è½½Word2Vecæ¨¡å‹ï¼Œè¿”å›None
            return None



    def calculate_npmi_coherence_window(self, topic_words: List[List[str]], window_size: int = 10) -> float:
        """
        è®¡ç®—NPMIè¿è´¯æ€§ (window=10) - RL-for-topic-modelsæ ‡å‡†æŒ‡æ ‡
        åŸºäºæ»‘åŠ¨çª—å£çš„è¯æ±‡å…±ç°ç»Ÿè®¡
        """
        if not self.reference_corpus or not topic_words:
            return 0.0

        # ç®€åŒ–çš„å®ç°ï¼šåŸºäºæ–‡æ¡£çº§åˆ«çš„å…±ç°
        coherence_scores = []

        for words in topic_words:
            if len(words) < 2:
                continue

            # è®¡ç®—è¯å¯¹çš„NPMI
            npmi_scores = []
            for i in range(len(words)):
                for j in range(i + 1, len(words)):
                    w1, w2 = words[i].lower(), words[j].lower()

                    # è®¡ç®—è¯æ±‡åœ¨æ–‡æ¡£ä¸­çš„å‡ºç°æ¬¡æ•°
                    count_w1 = sum(1 for doc in self.reference_corpus if w1 in doc.lower())
                    count_w2 = sum(1 for doc in self.reference_corpus if w2 in doc.lower())
                    count_both = sum(1 for doc in self.reference_corpus if w1 in doc.lower() and w2 in doc.lower())

                    if count_w1 > 0 and count_w2 > 0 and count_both > 0:
                        total_docs = len(self.reference_corpus)
                        p_w1 = count_w1 / total_docs
                        p_w2 = count_w2 / total_docs
                        p_both = count_both / total_docs

                        # è®¡ç®—PMI
                        pmi = math.log(p_both / (p_w1 * p_w2))
                        # æ ‡å‡†åŒ–ä¸ºNPMI
                        npmi = pmi / (-math.log(p_both))
                        npmi_scores.append(npmi)

            if npmi_scores:
                coherence_scores.append(np.mean(npmi_scores))

        return np.mean(coherence_scores) if coherence_scores else 0.0


        """è®¡ç®—ç¬¦åˆè¦æ±‚çš„ä¸»é¢˜æ¯”ä¾‹ï¼ˆ5-8ä¸ªå…³é”®è¯ï¼‰"""
        if not topics:
            return 0.0
        
        valid_count = sum(1 for topic in topics 
                         if 5 <= len(topic.get('keywords', [])) <= 8)
        
        return valid_count / len(topics)
    
    
    def _calculate_npmi(self, word1: str, word2: str) -> Optional[float]:
        """è®¡ç®—ä¸¤ä¸ªè¯çš„NPMIå€¼"""
        if not self.doc_counts:
            return None
        
        # è·å–è¯é¢‘
        count_w1 = self.doc_counts.get(word1, 0)
        count_w2 = self.doc_counts.get(word2, 0)
        
        if count_w1 == 0 or count_w2 == 0:
            return None
        
        # è®¡ç®—å…±ç°é¢‘ç‡
        cooccur_count = 0
        for doc in self.reference_corpus:
            words = set(doc.lower().split())
            if word1 in words and word2 in words:
                cooccur_count += 1
        
        if cooccur_count == 0:
            return None
        
        # è®¡ç®—æ¦‚ç‡
        p_w1 = count_w1 / self.total_docs
        p_w2 = count_w2 / self.total_docs
        p_w1_w2 = cooccur_count / self.total_docs
        
        # è®¡ç®—PMI
        pmi = math.log(p_w1_w2 / (p_w1 * p_w2))
        
        # è®¡ç®—NPMI
        npmi = pmi / (-math.log(p_w1_w2))
        
        return npmi
    
    def calculate_pmi_coherence(self, topic_words: List[List[str]]) -> float:
        """è®¡ç®—PMIè¿è´¯æ€§"""
        if not self.reference_corpus or not topic_words:
            return 0.0
        
        coherence_scores = []
        
        for words in topic_words:
            if len(words) < 2:
                continue
            
            word_pairs = list(combinations(words, 2))
            pair_scores = []
            
            for w1, w2 in word_pairs:
                pmi = self._calculate_pmi(w1, w2)
                if pmi is not None:
                    pair_scores.append(pmi)
            
            if pair_scores:
                coherence_scores.append(np.mean(pair_scores))
        
        return np.mean(coherence_scores) if coherence_scores else 0.0
    
    def _calculate_pmi(self, word1: str, word2: str) -> Optional[float]:
        """è®¡ç®—ä¸¤ä¸ªè¯çš„PMIå€¼"""
        if not self.doc_counts:
            return None
        
        count_w1 = self.doc_counts.get(word1, 0)
        count_w2 = self.doc_counts.get(word2, 0)
        
        if count_w1 == 0 or count_w2 == 0:
            return None
        
        cooccur_count = 0
        for doc in self.reference_corpus:
            words = set(doc.lower().split())
            if word1 in words and word2 in words:
                cooccur_count += 1
        
        if cooccur_count == 0:
            return None
        
        p_w1 = count_w1 / self.total_docs
        p_w2 = count_w2 / self.total_docs
        p_w1_w2 = cooccur_count / self.total_docs
        
        return math.log(p_w1_w2 / (p_w1 * p_w2))
    

    def _calculate_cv_coherence(self, word1: str, word2: str) -> Optional[float]:
        """è®¡ç®—C_Vè¿è´¯æ€§åˆ†æ•°"""
        if not self.doc_counts:
            return None

        # ç®€åŒ–çš„C_Vå®ç°ï¼Œä½¿ç”¨æ–‡æ¡£å…±ç°
        count_w1 = self.doc_counts.get(word1.lower(), 0)
        count_w2 = self.doc_counts.get(word2.lower(), 0)

        if count_w1 == 0 or count_w2 == 0:
            return None

        # è®¡ç®—å…±ç°
        cooccur_count = 0
        for doc in self.reference_corpus:
            words = set(doc.lower().split())
            if word1.lower() in words and word2.lower() in words:
                cooccur_count += 1

        if cooccur_count == 0:
            return None

        # ç®€åŒ–çš„C_Vè®¡ç®—
        p_w1_w2 = cooccur_count / self.total_docs
        p_w1 = count_w1 / self.total_docs
        p_w2 = count_w2 / self.total_docs

        if p_w1_w2 > 0 and p_w1 > 0 and p_w2 > 0:
            return math.log((p_w1_w2 + 1e-10) / (p_w1 * p_w2 + 1e-10))

        return None


    def calculate_word2vec_coherence(self, topic_words: List[List[str]]) -> float:
        """
        è®¡ç®—Word2Vecè¿è´¯æ€§ - RL-for-topic-modelsæŒ‡æ ‡
        ä½¿ç”¨è¯å‘é‡ä½™å¼¦ç›¸ä¼¼åº¦è¡¡é‡ä¸»é¢˜å†…è¯çš„è¯­ä¹‰ä¸€è‡´æ€§
        """
        try:
            # å°è¯•å¯¼å…¥gensimå’Œä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
            import gensim.downloader as api

            # ä½¿ç”¨é¢„è®­ç»ƒçš„Word2Vecæ¨¡å‹
            model = api.load("word2vec-google-news-300")

            coherence_scores = []

            for words in topic_words:
                if len(words) < 2:
                    continue

                # è¿‡æ»¤æ¨¡å‹ä¸­å­˜åœ¨çš„è¯
                valid_words = [word for word in words if word in model.key_to_index]

                if len(valid_words) < 2:
                    continue

                # è®¡ç®—è¯å¯¹çš„ä½™å¼¦ç›¸ä¼¼åº¦
                similarities = []
                for i in range(len(valid_words)):
                    for j in range(i + 1, len(valid_words)):
                        try:
                            sim = model.similarity(valid_words[i], valid_words[j])
                            similarities.append(sim)
                        except:
                            continue

                if similarities:
                    coherence_scores.append(np.mean(similarities))

            return np.mean(coherence_scores) if coherence_scores else 0.0

        except Exception as e:
            # å¦‚æœæ— æ³•åŠ è½½Word2Vecæ¨¡å‹ï¼Œè¿”å›None
            return None

    def _calculate_cv_score(self, word1: str, word2: str) -> Optional[float]:
        """è®¡ç®—C_Vè¿è´¯æ€§åˆ†æ•°"""
        if not self.doc_counts:
            return None

        # ç®€åŒ–çš„C_Vå®ç°ï¼Œä½¿ç”¨æ–‡æ¡£å…±ç°
        count_w1 = self.doc_counts.get(word1, 0)
        count_w2 = self.doc_counts.get(word2, 0)

        if count_w1 == 0 or count_w2 == 0:
            return None

        # è®¡ç®—å…±ç°
        cooccur_count = 0
        for doc in self.reference_corpus:
            words = set(doc.lower().split())
            if word1 in words and word2 in words:
                cooccur_count += 1

        if cooccur_count == 0:
            return None

        # ç®€åŒ–çš„C_Vè®¡ç®—
        p_w1_w2 = cooccur_count / self.total_docs
        p_w1 = count_w1 / self.total_docs
        p_w2 = count_w2 / self.total_docs

        if p_w1_w2 > 0 and p_w1 > 0 and p_w2 > 0:
            return math.log((p_w1_w2 + 1e-10) / (p_w1 * p_w2 + 1e-10))

        return None

    def _calculate_umass_score(self, word1: str, word2: str) -> Optional[float]:
        """è®¡ç®—UMassè¿è´¯æ€§åˆ†æ•°"""
        if not self.doc_counts:
            return None

        count_w1 = self.doc_counts.get(word1, 0)
        count_w2 = self.doc_counts.get(word2, 0)

        if count_w1 == 0 or count_w2 == 0:
            return None

        # è®¡ç®—å…±ç°
        cooccur_count = 0
        for doc in self.reference_corpus:
            words = set(doc.lower().split())
            if word1 in words and word2 in words:
                cooccur_count += 1

        # UMasså…¬å¼: log((D(w_i, w_j) + 1) / D(w_j))
        return math.log((cooccur_count + 1) / count_w2)
    
    def calculate_max_topic_overlap(self, topic_words: List[List[str]]) -> float:
        """å‘åå…¼å®¹çš„æ–¹æ³•å"""
        return self.calculate_max_jaccard_overlap(topic_words)

    def calculate_topic_similarity(self, topic_words: List[List[str]]) -> float:
        """å‘åå…¼å®¹çš„æ–¹æ³•å"""
        return self.calculate_jaccard_similarity(topic_words)

    def calculate_max_jaccard_overlap_old(self, topic_words: List[List[str]]) -> float:
        """è®¡ç®—æœ€å¤§ä¸»é¢˜é‡å åº¦"""
        if len(topic_words) < 2:
            return 0.0
        
        max_overlap = 0.0
        
        for i in range(len(topic_words)):
            for j in range(i + 1, len(topic_words)):
                set1 = set(topic_words[i])
                set2 = set(topic_words[j])
                
                if len(set1) > 0 and len(set2) > 0:
                    overlap = len(set1.intersection(set2)) / min(len(set1), len(set2))
                    max_overlap = max(max_overlap, overlap)
        
        return max_overlap
    
    def calculate_rbo(self, list1: List[List[str]], list2: List[List[str]], p: float = 0.9) -> float:
        """
        è®¡ç®—RBO (Rank-Biased Overlap)
        ç”¨äºæ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹çš„ä¸»é¢˜è¯æ’åºç›¸ä¼¼åº¦
        
        Args:
            list1, list2: ä¸¤ä¸ªä¸»é¢˜è¯åˆ—è¡¨
            p: RBOå‚æ•°ï¼Œæ§åˆ¶å¯¹æ’åºä½ç½®çš„é‡è§†ç¨‹åº¦

        Returns:
            RBOåˆ†æ•° (0-1)
        """
        if len(list1) != len(list2):
            return 0.0

        rbo_scores = []
        
        for i in range(min(len(list1), len(list2))):
            words1 = list1[i]
            words2 = list2[i]
            
            rbo = self._rbo_score(words1, words2, p)
            rbo_scores.append(rbo)
        
        return np.mean(rbo_scores) if rbo_scores else 0.0
    
    def _rbo_score(self, list1: List[str], list2: List[str], p: float) -> float:
        """è®¡ç®—ä¸¤ä¸ªåˆ—è¡¨çš„RBOåˆ†æ•°"""
        if not list1 or not list2:
            return 0.0
        
        max_len = max(len(list1), len(list2))
        min_len = min(len(list1), len(list2))
        
        # è®¡ç®—é‡å 
        overlap = 0.0
        for d in range(1, min_len + 1):
            set1 = set(list1[:d])
            set2 = set(list2[:d])
            overlap += len(set1.intersection(set2)) / d * (p ** (d - 1))
        
        # æ·»åŠ å°¾éƒ¨æƒé‡
        if max_len > min_len:
            overlap += (len(set(list1[:min_len]).intersection(set(list2[:min_len]))) / min_len) * (p ** min_len) * (1 - p) / (1 - p)
        
        return (1 - p) * overlap
    
    def print_evaluation_report(self, results: Dict[str, float]):
        """æ‰“å°è¯„æµ‹æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ“Š LLMä¸»é¢˜åˆ†æè¯„æµ‹æŠ¥å‘Š")
        print("="*80)
        
        # print(f"\nğŸ¯ ä¸»é¢˜è´¨é‡æŒ‡æ ‡:")
        # print(f"   å¹³å‡å…³é”®è¯æ•°é‡: {results.get('avg_keywords_per_topic', 0):.2f}")
        # print(f"   å…³é”®è¯æ•°é‡æ–¹å·®: {results.get('keyword_count_variance', 0):.2f}")
        # print(f"   ç¬¦åˆè¦æ±‚ä¸»é¢˜æ¯”ä¾‹: {results.get('valid_topics_ratio', 0):.2%}")
        
        print(f"\nğŸ¨ ä¸»é¢˜å¤šæ ·æ€§æŒ‡æ ‡:")
        print(f"   ä¸»é¢˜å¤šæ ·æ€§: {results.get('diversity', 0):.3f}")
        print(f"   ç‹¬ç‰¹è¯æ±‡æ¯”ä¾‹: {results.get('unique_words_ratio', 0):.3f}")
        print(f"   å¹³å‡ä¸»é¢˜ç›¸ä¼¼åº¦: {results.get('avg_topic_similarity', 0):.3f}")
        print(f"   æœ€å¤§ä¸»é¢˜é‡å åº¦: {results.get('max_topic_overlap', 0):.3f}")
        
        if 'npmi_coherence' in results:
            print(f"\nğŸ”— è¯­ä¹‰è¿è´¯æ€§æŒ‡æ ‡:")
            print(f"   NPMIè¿è´¯æ€§: {results.get('npmi_coherence', 0):.3f}")
            print(f"   PMIè¿è´¯æ€§: {results.get('pmi_coherence', 0):.3f}")
        
        print(f"\nğŸ“ˆ è¯„æµ‹æ€»ç»“:")
        quality_score = (results.get('valid_topics_ratio', 0) + 
                        results.get('diversity', 0) + 
                        (1 - results.get('avg_topic_similarity', 1))) / 3
        print(f"   ç»¼åˆè´¨é‡åˆ†æ•°: {quality_score:.3f}")
        
        # # ç»™å‡ºå»ºè®®
        # print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        # if results.get('valid_topics_ratio', 0) < 0.8:
        #     print("   - å…³é”®è¯æ•°é‡æ§åˆ¶éœ€è¦æ”¹è¿›ï¼Œå»ºè®®ä¼˜åŒ–æç¤ºè¯")
        # if results.get('diversity', 0) < 0.7:
        #     print("   - ä¸»é¢˜å¤šæ ·æ€§è¾ƒä½ï¼Œå»ºè®®å¢åŠ ä¸»é¢˜æ•°é‡æˆ–æ”¹è¿›ç®—æ³•")
        # if results.get('avg_topic_similarity', 0) > 0.3:
        #     print("   - ä¸»é¢˜é—´ç›¸ä¼¼åº¦è¾ƒé«˜ï¼Œå»ºè®®æé«˜ä¸»é¢˜åŒºåˆ†åº¦")
        # if results.get('npmi_coherence', 0) < 0.1:
        #     print("   - è¯­ä¹‰è¿è´¯æ€§è¾ƒä½ï¼Œå»ºè®®æ”¹è¿›ä¸»é¢˜è¯é€‰æ‹©ç­–ç•¥")
