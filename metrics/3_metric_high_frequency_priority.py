#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜é¢‘ä¸»é¢˜ä¼˜å…ˆç”Ÿæˆè¯„ä¼°æŒ‡æ ‡

åˆ¤æ–­ç”Ÿæˆçš„ä¸»é¢˜æ˜¯å¦ä¼˜å…ˆä¸ºæºæ–‡æœ¬ä¸­å‡ºç°æœ€é¢‘ç¹çš„ä¸»é¢˜
ç»Ÿè®¡æ¯ä¸ªä¸»é¢˜ä¸‹é¢çš„æ–‡æœ¬æ•°é‡å‡å€¼å’Œæ–¹å·®
å‡å€¼è¶Šå¤§ï¼Œè¯æ˜ç”Ÿæˆäº†é«˜é¢‘ä¸»é¢˜ï¼›æ–¹å·®è¶Šå°ï¼Œè¯æ˜æ•ˆæœç¨³å®š
"""

import json
import pandas as pd
import numpy as np
from typing import Dict, Any, List
from collections import Counter
import os

# é…ç½®åŒºåŸŸ
INPUT_FILE = "data/NYT_sampled.csv"
JSON_FILE = "llm_analysis/results/topic_analysis_NYT_sampled_meta_llama_llama_4_maverick.json"
GROUND_TRUTH_FILE = ""  # å¦‚æœæœ‰çœŸå®æ ‡æ³¨æ–‡ä»¶

def analyze_high_frequency_priority(json_file: str, csv_file: str = None) -> Dict[str, Any]:
    """
    è¯„ä¼°é«˜é¢‘ä¸»é¢˜ä¼˜å…ˆç”Ÿæˆ
    
    Args:
        json_file (str): ç”Ÿæˆçš„ä¸»é¢˜åˆ†æç»“æœJSONæ–‡ä»¶
        csv_file (str): åŸå§‹CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œç”¨äºå¯¹æ¯”ï¼‰
        
    Returns:
        Dict: è¯„ä¼°ç»“æœ
    """
    print("ğŸ”¥ è¯„ä¼°é«˜é¢‘ä¸»é¢˜ä¼˜å…ˆç”Ÿæˆ...")
    print(f"   ğŸ“ JSONæ–‡ä»¶: {json_file}")
    if csv_file:
        print(f"   ğŸ“ CSVæ–‡ä»¶: {csv_file}")
    
    try:
        # è¯»å–ç”Ÿæˆçš„ä¸»é¢˜åˆ†æç»“æœ
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        topics = data.get('topics', [])
        if not topics:
            return {"error": "JSONæ–‡ä»¶ä¸­æœªæ‰¾åˆ°ä¸»é¢˜ä¿¡æ¯"}
        
        # ç»Ÿè®¡æ¯ä¸ªä¸»é¢˜çš„æ–‡æœ¬åˆ†é…æ•°é‡
        topic_frequencies = []
        topic_info = []
        
        for topic in topics:
            if isinstance(topic, dict):
                topic_num = topic.get('topic_num', 'Unknown')
                summary = topic.get('summary', 'No summary')
                keywords = topic.get('keywords', [])
                source_titles = topic.get('source_titles_with_ids', [])
                
                frequency = len(source_titles)
                topic_frequencies.append(frequency)
                
                topic_info.append({
                    'topic_num': topic_num,
                    'summary': summary,
                    'keywords': keywords,
                    'frequency': frequency,
                    'source_count': len(source_titles)
                })
        
        if not topic_frequencies:
            return {"error": "æœªæ‰¾åˆ°æœ‰æ•ˆçš„ä¸»é¢˜é¢‘ç‡æ•°æ®"}
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        mean_frequency = np.mean(topic_frequencies)
        variance = np.var(topic_frequencies)
        std_dev = np.std(topic_frequencies)
        
        # æ’åºä¸»é¢˜æŒ‰é¢‘ç‡
        sorted_topics = sorted(topic_info, key=lambda x: x['frequency'], reverse=True)
        
        # è®¡ç®—é«˜é¢‘ä¸»é¢˜æ¯”ä¾‹ï¼ˆå‰20%çš„ä¸»é¢˜ï¼‰
        top_20_percent_count = max(1, len(sorted_topics) // 5)
        high_freq_topics = sorted_topics[:top_20_percent_count]
        high_freq_total = sum(t['frequency'] for t in high_freq_topics)
        total_frequency = sum(topic_frequencies)
        high_freq_ratio = high_freq_total / total_frequency if total_frequency > 0 else 0
        
        # è¯„ä¼°ç¨³å®šæ€§ï¼ˆæ–¹å·®è¶Šå°è¶Šç¨³å®šï¼‰
        stability_score = 1 / (1 + variance/mean_frequency) if mean_frequency > 0 else 0
        
        # è¯„ä¼°é«˜é¢‘ä¼˜å…ˆæ€§ï¼ˆå‡å€¼è¶Šå¤§è¶Šå¥½ï¼‰
        priority_score = mean_frequency / max(topic_frequencies) if topic_frequencies else 0
        
        results = {
            "metric_name": "é«˜é¢‘ä¸»é¢˜ä¼˜å…ˆç”Ÿæˆ",
            "total_topics": len(topic_frequencies),
            "mean_frequency": round(mean_frequency, 2),
            "variance": round(variance, 2),
            "standard_deviation": round(std_dev, 2),
            "high_frequency_ratio": round(high_freq_ratio, 4),
            "stability_score": round(stability_score, 4),
            "priority_score": round(priority_score, 4),
            "frequency_distribution": topic_frequencies,
            "top_topics": high_freq_topics[:10],  # å‰10ä¸ªé«˜é¢‘ä¸»é¢˜
            "evaluation": {
                "high_frequency_priority": "ä¼˜ç§€" if priority_score > 0.7 else "è‰¯å¥½" if priority_score > 0.5 else "ä¸€èˆ¬",
                "stability": "ç¨³å®š" if stability_score > 0.7 else "ä¸­ç­‰" if stability_score > 0.5 else "ä¸ç¨³å®š",
                "overall_assessment": "ä¼˜ç§€" if (priority_score > 0.7 and stability_score > 0.7) else "è‰¯å¥½" if (priority_score > 0.5 and stability_score > 0.5) else "éœ€æ”¹è¿›"
            }
        }
        
        # è¾“å‡ºç»“æœ
        print(f"\nğŸ”¥ é«˜é¢‘ä¸»é¢˜ä¼˜å…ˆç”Ÿæˆåˆ†æç»“æœ:")
        print(f"   ğŸ“Š æ€»ä¸»é¢˜æ•°: {results['total_topics']}")
        print(f"   ğŸ“Š å¹³å‡é¢‘ç‡: {results['mean_frequency']}")
        print(f"   ğŸ“Š æ–¹å·®: {results['variance']} (è¶Šå°è¶Šç¨³å®š)")
        print(f"   ğŸ“Š æ ‡å‡†å·®: {results['standard_deviation']}")
        print(f"   ğŸ“Š é«˜é¢‘ä¸»é¢˜å æ¯”: {results['high_frequency_ratio']:.2%}")
        print(f"   ğŸ“Š ç¨³å®šæ€§å¾—åˆ†: {results['stability_score']:.4f}")
        print(f"   ğŸ“Š ä¼˜å…ˆæ€§å¾—åˆ†: {results['priority_score']:.4f}")
        print(f"   ğŸ“Š æ•´ä½“è¯„ä¼°: {results['evaluation']['overall_assessment']}")
        
        print(f"\nğŸ† å‰10ä¸ªé«˜é¢‘ä¸»é¢˜:")
        for i, topic in enumerate(high_freq_topics[:10], 1):
            print(f"   {i}. ä¸»é¢˜{topic['topic_num']}: {topic['frequency']}ç¯‡ - {topic['summary'][:50]}...")
        
        return results
        
    except FileNotFoundError:
        return {"error": f"æ–‡ä»¶æœªæ‰¾åˆ°: {json_file}"}
    except json.JSONDecodeError:
        return {"error": f"JSONæ–‡ä»¶æ ¼å¼é”™è¯¯: {json_file}"}
    except Exception as e:
        return {"error": f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"}

def save_results(results: Dict[str, Any], output_file: str = "high_frequency_priority_results.json"):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = "C:/Users/1/Desktop/TopMost/metric_result"
        os.makedirs(output_dir, exist_ok=True)

        # æ„å»ºå®Œæ•´è·¯å¾„
        full_path = os.path.join(output_dir, output_file)

        with open(full_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {full_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ é«˜é¢‘ä¸»é¢˜ä¼˜å…ˆç”Ÿæˆè¯„ä¼°")
    print("="*60)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(JSON_FILE):
        print(f"âŒ JSONæ–‡ä»¶ä¸å­˜åœ¨: {JSON_FILE}")
        return
    
    # è¿è¡Œåˆ†æ
    results = analyze_high_frequency_priority(JSON_FILE, INPUT_FILE if os.path.exists(INPUT_FILE) else None)
    
    if "error" in results:
        print(f"âŒ åˆ†æå¤±è´¥: {results['error']}")
        return
    
    # ä¿å­˜ç»“æœ
    save_results(results)
    
    print("\nğŸ‰ åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main()
